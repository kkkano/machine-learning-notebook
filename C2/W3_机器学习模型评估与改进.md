# ???????????

?????????????????????????????????????????????????????????????????????????????????

## ??

- [1 - ?????](#1)
- [2 - ?????????????](#2)
  - [2.1 ?????](#2.1)
  - [2.2 ???????????????](#2.2)
  - [2.3 ????????????](#2.3)
- [3 - ?????](#3)
  - [3.1 ??????????????](#3.1)
  - [3.2 ?????????](#3.2)
  - [3.3 ?????](#3.3)
  - [3.4 ??????????????](#3.4)
- [4 - ????????????](#4)
  - [4.1 ???](#4.1)
  - [4.2 ??????????????](#4.2)
- [5 - ?????](#5)
  - [5.1 ????](#5.1)
- [6 - ???](#6)
- [7 - ??????????](#7)
  - [7.1 ??](#7.1)

---

<a name="1"></a>
## 1 - ?????

?????????????? Python ?????????????????????????????????????????

- **[NumPy](https://numpy.org/)**?Python ???????????????
- **[Matplotlib](https://matplotlib.org/)**??????????????????????
- **[Scikit-learn](https://scikit-learn.org/stable/)**?????????????????
- **[TensorFlow](https://www.tensorflow.org/)**?????????????

```python
import numpy as np
%matplotlib widget
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.activations import relu,linear
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from tensorflow.keras.optimizers import Adam

import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)

tf.keras.backend.set_floatx('float64')
from assigment_utils import *

tf.autograph.set_verbosity(0)
```

??????????????????????

---

<a name="2"></a>
## 2 - ?????????????

![??????](/static/images/MLc2/output2w3_01.png)

???????????????????????????????????????????????????????????**?**?????

????????????????????????????

- ???????????????????
  - ??????????????
  - ???????????????????
- ??????????????

<a name="2.1"></a>
### 2.1 ?????

?????? 20-40% ???????????????? `sklearn` ? [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) ?????????????????????????

```python
# ??????
X, y, x_ideal, y_ideal = gen_data(18, 2, 0.7)
print("X.shape", X.shape, "y.shape", y.shape)

# ?? sklearn ??????
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)
print("X_train.shape", X_train.shape, "y_train.shape", y_train.shape)
print("X_test.shape", X_test.shape, "y_test.shape", y_test.shape)
```
> X.shape (18,) y.shape (18,)
> X_train.shape (12,) y_train.shape (12,)
> X_test.shape (6,) y_test.shape (6,)

```python
fig, ax = plt.subplots(1,1,figsize=(4,4))
ax.plot(x_ideal, y_ideal, "--", color = "orangered", label="y_ideal", lw=1)
ax.set_title("Training, Test",fontsize = 14)
ax.set_xlabel("x")
ax.set_ylabel("y")

ax.scatter(X_train, y_train, color = "red",           label="train")
ax.scatter(X_test, y_test,   color = dlc["dlblue"],   label="test")
ax.legend(loc='upper left')
plt.show()
```
![???2](/static/images/MLc2/output2w3_02.png)

<a name="2.2"></a>

### 2.2 ???????????????

????????????????????????????????????


$$
J_{\text{test}}(\mathbf{w}, b) = \frac{1}{2m_{\text{test}}} \sum_{i=0}^{m_{\text{test}}-1} \left( f_{\mathbf{w}, b}(\mathbf{x}^{(i)}_{\text{test}}) - y^{(i)}_{\text{test}} \right)^2
$$

#### ?? 1

????? `eval_mse` ???????????????

```python
def eval_mse(y, yhat):
    """
    ????????????
    ??:
        y (ndarray): ?? (m,) ? (m,1)?????????
        yhat (ndarray): ?? (m,) ? (m,1)?????????
    ??:
        err (scalar): ????
    """
    m = len(y)
    err = 0.0
    for i in range(m):
        err_i = (yhat[i] - y[i]) ** 2
        err += err_i
    err = err / (2 * m)
    return err
```

<a name="2.3"></a>
### 2.3 ????????????

???????????????????????????? `sklearn` ??????????????

- ??????????????????????????????
- ???????????
- ???????????

```python
# ? sklearn ?????????????????
degree = 10
lmodel = lin_model(degree)
lmodel.fit(X_train, y_train)

# ?????????????
yhat = lmodel.predict(X_train)
err_train = lmodel.mse(y_train, yhat)

# ???????????
yhat = lmodel.predict(X_test)
err_test = lmodel.mse(y_test, yhat)
```
```python
print(f"training err {err_train:0.2f}, test err {err_test:0.2f}")
```
>training err 58.01, test err 171215.01

????????????????????????????????????????????????????????????????????????????????????????????????????? 1) ????2) ??????3) ????????

```python
# ??????
x = np.linspace(0, int(X.max()), 100)
y_pred = lmodel.predict(x).reshape(-1, 1)

plt_train_test(X_train, y_train, X_test, y_test, x, y_pred, x_ideal, y_ideal, degree)
```

---

![???3](/static/images/MLc2/output2w3_03.png)

?????????????????????????????????????????

|                 data ?? | % of total ??????? | Description ??                                             |
| ------------------------: | :-----------------------: | :----------------------------------------------------------- |
|             training ?? |            60             | Data used to tune model parameters ??w and ??b in training or fitting ???????? ??w ?? ??b ?????????? |
| cross-validation ???? |            20             | Data used to tune other model parameters like degree of polynomial, regularization or the architecture of a neural network. ???????????????????????????????? |
|                 test ?? |            20             | Data used to test the model after tuning to gauge performance on new data ???????????????????? |

????????????????????? `train_test_split` from `sklearn` ????????????????

```python
# Generate  data
X,y, x_ideal,y_ideal = gen_data(40, 5, 0.7)
print("X.shape", X.shape, "y.shape", y.shape)

#split the data using sklearn routine 
X_train, X_, y_train, y_ = train_test_split(X,y,test_size=0.40, random_state=1)
X_cv, X_test, y_cv, y_test = train_test_split(X_,y_,test_size=0.50, random_state=1)
print("X_train.shape", X_train.shape, "y_train.shape", y_train.shape)
print("X_cv.shape", X_cv.shape, "y_cv.shape", y_cv.shape)
print("X_test.shape", X_test.shape, "y_test.shape", y_test.shape)
```

>X.shape (40,) y.shape (40,)
X_train.shape (24,) y_train.shape (24,)
X_cv.shape (8,) y_cv.shape (8,)
X_test.shape (8,) y_test.shape (8,)


<a name="3"></a>

## 3 - ?????

![?????](/static/images/MLc1/output2w3_04.png "?????" align="right" style="width:500px; padding: 10px 20px;") 

?????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

<a name="3.1"></a>
### 3.1 ??????????????

???????????????????????????????????????????

```python
fig, ax = plt.subplots(1, 1, figsize=(4, 4))
ax.plot(x_ideal, y_ideal, "--", color="orangered", label="y_ideal", lw=1)
ax.set_title("Training, CV, Test", fontsize=14)
ax.set_xlabel("x")
ax.set_ylabel("y")

ax.scatter(X_train, y_train, color="red", label="train")
ax.scatter(X_cv, y_cv, color="orange", label="cv")
ax.scatter(X_test, y_test, color="blue", label="test")
ax.legend(loc='upper left')
plt.show()
```

![???5](/static/images/MLc2/output2w3_05.png)

<a name="3.2"></a>

### 3.2 ?????????

???????????????????????????????????????????????????????????????????????????????????????????????

???????????????????????????????? [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) ?????????????????

```python
max_degree = 9
err_train = np.zeros(max_degree)
err_cv = np.zeros(max_degree)
x = np.linspace(0, int(X.max()), 100)
y_pred = np.zeros((100, max_degree))

for degree in range(max_degree):
    lmodel = lin_model(degree + 1)
    lmodel.fit(X_train, y_train)
    yhat = lmodel.predict(X_train)
    err_train[degree] = lmodel.mse(y_train, yhat)
    yhat = lmodel.predict(X_cv)
    err_cv[degree] = lmodel.mse(y_cv, yhat)
    y_pred[:, degree] = lmodel.predict(x)

optimal_degree = np.argmin(err_cv) + 1
```

????????

```python
plt.close("all")
plt_optimal_degree(X_train, y_train, X_cv, y_cv, x, y_pred, x_ideal, y_ideal,
                   err_train, err_cv, optimal_degree, max_degree)
```

![???6](/static/images/MLc2/output2w3_06.png)

????????????????????????????????????????????????????????????????????????????

- ????????????????????? 1 ?????????????????????????????????????????
- ??????
  - ????????????????????????????????
  - ?????????????????????????????????????????????????????

?????????????????????????????????????????????????????????????????????????

<a name="3.3"></a>
### 3.3 ?????

???????????*???*??????????????????????????????? ??

?????????????????????????????

```python
lambda_range = np.array([0.0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100])
num_steps = len(lambda_range)
degree = 10
err_train = np.zeros(num_steps)
err_cv = np.zeros(num_steps)
x = np.linspace(0, int(X.max()), 100)
y_pred = np.zeros((100, num_steps))

for i in range(num_steps):
    lambda_ = lambda_range[i]
    lmodel = lin_model(degree, regularization=True, lambda_=lambda_)
    lmodel.fit(X_train, y_train)
    yhat = lmodel.predict(X_train)
    err_train[i] = lmodel.mse(y_train, yhat)
    yhat = lmodel.predict(X_cv)
    err_cv[i] = lmodel.mse(y_cv, yhat)
    y_pred[:, i] = lmodel.predict(x)

optimal_reg_idx = np.argmin(err_cv)
```

```python
plt.close("all")
plt_tune_regularization(X_train, y_train, X_cv, y_cv, x, y_pred, err_train, err_cv, optimal_reg_idx, lambda_range)
```

![???7](/static/images/MLc2/output2w3_07.png)

??????????????????????????????????????????????????????? ? ???????????????????? 10?

<a name="3.4"></a>
### 3.4 ??????????????

???????????????????????????????????

```python
X_train, y_train, X_cv, y_cv, x, y_pred, err_train, err_cv, m_range, degree = tune_m()
plt_tune_m(X_train, y_train, X_cv, y_cv, x, y_pred, err_train, err_cv, m_range, degree)
```

![???8](/static/images/MLc2/output2w3_08.png)

?????????????????????????????????????????????????? m ????????????????????????????????????????????????????????????????????????????????????????????????????

> **???** ?????????????????????????????

---

<a name="4"></a>
## 4 - ????????????

????????????????????????????????????????????????????

<a name="4.1"></a>
### 4.1 ???

?????????????????????????CV?????????????????????????????????????

```python
# ????????
X, y, centers, classes, std = gen_blobs()

# ???????? CV ??????
X_train, X_, y_train, y_ = train_test_split(X, y, test_size=0.50, random_state=1)
X_cv, X_test, y_cv, y_test = train_test_split(X_, y_, test_size=0.20, random_state=1)
print("X_train.shape:", X_train.shape, "X_cv.shape:", X_cv.shape, "X_test.shape:", X_test.shape)
```
>X_train.shape: (400, 2) X_cv.shape: (320, 2) X_test.shape: (80, 2)
```python
plt_train_eq_dist(X_train, y_train, classes, X_cv, y_cv, centers, std)
```

![???9](/static/images/MLc2/output2w3_09.png)

??????????????????????????????????????????????????????????????????????????????????????????????????????????

????????????????????????????????????????????????????????????????????????????????? 8% ??????

<a name="4.2"></a>
### 4.2 ??????????????

??????????????????????

$$
J_{cv} = \frac{1}{m} \sum_{i=0}^{m-1} 
\begin{cases} 
1, & \text{if } \hat{y}^{(i)} \neq y^{(i)} \\ 
0, & \text{otherwise} 
\end{cases}
$$

#### ?? 2

????? `eval_cat_err` ?????????????????????????????????[one-hot ??](https://en.wikipedia.org/wiki/One-hot)?

```python
def eval_cat_err(y, yhat):
    """
    ???????
    ??:
        y (ndarray): ?? (m,) ? (m,1)?????????
        yhat (ndarray): ?? (m,) ? (m,1)?????????
    ??:
        cerr (scalar): ????
    """
    m = len(y)
    incorrect = 0
    for i in range(m):
        if yhat[i] != y[i]:
            incorrect += 1
    cerr = incorrect / m
    return cerr
```

---

```python
y_hat = np.array([1, 2, 0])
y_tmp = np.array([1, 2, 3])
print(f"categorization error {np.squeeze(eval_cat_err(y_hat, y_tmp)):0.3f}, expected:0.333" )
y_hat = np.array([[1], [2], [0], [3]])
y_tmp = np.array([[1], [2], [1], [3]])
print(f"categorization error {np.squeeze(eval_cat_err(y_hat, y_tmp)):0.3f}, expected:0.250" )

test_eval_cat_err(eval_cat_err)
```
>categorization error 0.333, expected:0.333
categorization error 0.250, expected:0.250


<a name="5"></a>

## 5 - ?????

???????????????????????????????????????????????????

#### ?? 3

?????????????????

- ?? 120 ???? Dense ??relu ??
- ?? 40 ???? Dense ??relu ??
- ?? 6 ???? Dense ????????? softmax?

???????????

- ????? `SparseCategoricalCrossentropy`????? `from_logits=True`
- Adam ???????? 0.01

```python
tf.random.set_seed(1234)
model = Sequential(
    [
        Dense(120, activation='relu', name="L1"),
        Dense(40, activation='relu', name="L2"),
        Dense(classes, activation='linear', name="L3")
    ], name="Complex"
)
model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(0.01),
)
```

```python
model.fit(X_train, y_train, epochs=1000)
```

```py
model.summary()
model_test(model, classes, X_train.shape[1]) 
```

```text
Model: "Complex"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 L1 (Dense)                  (None, 120)               360       
                                                                 
 L2 (Dense)                  (None, 40)                4840      
                                                                 
 L3 (Dense)                  (None, 6)                 246       
                                                                 
=================================================================
Total params: 5,446
Trainable params: 5,446
Non-trainable params: 0
_________________________________________________________________
```

????????????????????????????????????????????????

```python
training_cerr_complex = eval_cat_err(y_train, model_predict(X_train))
cv_cerr_complex = eval_cat_err(y_cv, model_predict(X_cv))
print(f"????????????: {training_cerr_complex:0.3f}")
print(f"?????CV?????: {cv_cerr_complex:0.3f}")
```
>categorization error, training,  complex model: 0.003
categorization error, cv,  complex model: 0.122


<a name="5.1"></a>

### 5.1 ????

????????????

#### ?? 4

?????????????????

- ?? 6 ???? Dense ??relu ??
- ?? 6 ???? Dense ??????

???????????

- ????? `SparseCategoricalCrossentropy`??? `from_logits=True`
- Adam ???????? 0.01

```python
tf.random.set_seed(1234)
model_s = Sequential(
    [
        Dense(6, activation='relu', name="L1"),
        Dense(classes, activation='linear', name="L2")
    ], name="Simple"
)
model_s.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(0.01),
)
```

```python
model_s.fit(X_train, y_train, epochs=1000)
```

```python
model_s.summary()
model_s_test(model_s, classes, X_train.shape[1])
```

```python
#make a model for plotting routines to call
model_predict_s = lambda Xl: np.argmax(tf.nn.softmax(model_s.predict(Xl)).numpy(),axis=1)
plt_nn(model_predict_s,X_train,y_train, classes, X_cv, y_cv, suptitle="Simple Model")
```

```text
Model: "Simple"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 L1 (Dense)                  (None, 6)                 18        
                                                                 
 L2 (Dense)                  (None, 6)                 42        
                                                                 
=================================================================
Total params: 60
Trainable params: 60
Non-trainable params: 0
_________________________________________________________________
```

????????????????????????

```python
training_cerr_simple = eval_cat_err(y_train, model_predict_s(X_train))
cv_cerr_simple = eval_cat_err(y_cv, model_predict_s(X_cv))
print(f"????????????: {training_cerr_simple:0.3f}, ????: {training_cerr_complex:0.3f}")
print(f"?????CV?????: {cv_cerr_simple:0.3f}, ????: {cv_cerr_complex:0.3f}")
```

>categorization error, training, simple model, 0.062, complex model: 0.003
categorization error, cv,       simple model, 0.087, complex model: 0.122

????????????????????????????????????????

---

<a name="6"></a>
## 6 - ???

????????????????????????????????????????

#### ?? 5

????????????????????????????

- ?? 120 ???? Dense ??relu ???`kernel_regularizer=tf.keras.regularizers.l2(0.1)`
- ?? 40 ???? Dense ??relu ???`kernel_regularizer=tf.keras.regularizers.l2(0.1)`
- ?? 6 ???? Dense ??????

???????????

- ????? `SparseCategoricalCrossentropy`??? `from_logits=True`
- Adam ???????? 0.01

```python
tf.random.set_seed(1234)
model_r = Sequential(
    [
        Dense(120, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), name="L1"),
        Dense(40, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.1), name="L2"),
        Dense(classes, activation='linear', name="L3")
    ], name="ComplexRegularized"
)
model_r.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=tf.keras.optimizers.Adam(0.01),
)
```

```python
model_r.fit(X_train, y_train, epochs=1000)
```

```python
model_r.summary()
model_r_test(model_r, classes, X_train.shape[1]) 
```

```
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 L1 (Dense)                  (None, 120)               360       
                                                                 
 L2 (Dense)                  (None, 40)                4840      
                                                                 
 L3 (Dense)                  (None, 6)                 246       
                                                                 
=================================================================
Total params: 5,446
Trainable params: 5,446
Non-trainable params: 0
_________________________________________________________________
```

```python
#make a model for plotting routines to call
model_predict_r = lambda Xl: np.argmax(tf.nn.softmax(model_r.predict(Xl)).numpy(),axis=1)
plt_nn(model_predict_r, X_train,y_train, classes, X_cv, y_cv, suptitle="Regularized")
```

???????????????????????????

```python
training_cerr_reg = eval_cat_err(y_train, model_predict_r(X_train))
cv_cerr_reg = eval_cat_err(y_cv, model_predict_r(X_cv))
print(f"?????????????: {training_cerr_reg:0.3f}, ????: {training_cerr_simple:0.3f}, ????: {training_cerr_complex:0.3f}")
print(f"?????CV??????: {cv_cerr_reg:0.3f}, ????: {cv_cerr_simple:0.3f}, ????: {cv_cerr_complex:0.3f}")
```

>categorization error, training, regularized: 0.072, simple model, 0.062, complex model: 0.003
categorization error, cv,       regularized: 0.066, simple model, 0.087, complex model: 0.122

????????????????????????????????????

---

<a name="7"></a>
## 7 - ??????????

??????????????????????????????????????????????????????????????

```python
tf.random.set_seed(1234)
lambdas = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3]
models = [None] * len(lambdas)

for i in range(len(lambdas)):
    lambda_ = lambdas[i]
    models[i] = Sequential(
        [
            Dense(120, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),
            Dense(40, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(lambda_)),
            Dense(classes, activation='linear')
        ]
    )
    models[i].compile(
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer=tf.keras.optimizers.Adam(0.01),
    )
    models[i].fit(X_train, y_train, epochs=1000)
    print(f"?? lambda = {lambda_}")
```

```python
plot_iterate(lambdas, models, X_train, y_train, X_cv, y_cv)
```

??????????????????????????????????????????? > 0.01 ???????????

<a name="7.1"></a>
### 7.1 ??

?????????????????????????????????

```python
plt_compare(X_test, y_test, classes, model_predict_s, model_predict_r, centers)
```

![???10](/static/images/MLc2/output2w3_010.png)

?????????????????????????????????????????????????

---

## ??

?????????????????????????????????????????
- ?????????????????????????
- ???????????????????????????????????????????????????
- ??????????????????????????????????????????

???????????????????????????????????????????????????????????????????????????
